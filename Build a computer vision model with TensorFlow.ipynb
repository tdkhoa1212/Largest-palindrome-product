{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label Description\n",
    "\n",
    "0 T-shirt/top\n",
    "\n",
    "1 Trouser\n",
    "\n",
    "2 Pullover\n",
    "\n",
    "3 Dress\n",
    "\n",
    "4 Coat\n",
    "\n",
    "5 Sandal\n",
    "\n",
    "6 Shirt\n",
    "\n",
    "7 Sneaker\n",
    "\n",
    "8 Bag\n",
    "\n",
    "9 Ankle boot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs={}):\n",
    "    if(logs.get('accuracy')>0.95):\n",
    "      print(\"\\nReached 95% accuracy so cancelling training!\")\n",
    "      self.model.stop_training = True\n",
    "\n",
    "callbacks = myCallback()\n",
    "#===================================================================================\n",
    "mnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "# Download dataset========================================================================\n",
    "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# treat all values as between 0 and 1=====================================================\n",
    "training_images=training_images/255.0\n",
    "test_images=test_images/255.0\n",
    "\n",
    "# Design the model========================================================================\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "# Sequential: defines a sequence of layers in the neural network.\n",
    "# Flatten: takes a square and turns it into a one-dimensional vector.\n",
    "# Dense: adds a layer of neurons.\n",
    "# Activation functions: tell each layer of neurons what to do. There are lots of options, but use these for now:\n",
    "# Relu: effectively means that if X is greater than 0 return X, else return 0. It only passes values of 0 or greater to the next layer in the network.\n",
    "# Softmax takes a set of values, and effectively picks the biggest one. For example, if the output of the last layer looks like [0.1, 0.1, 0.05, 0.1, 9.5, 0.1, 0.05, 0.05, 0.05], then it saves you from having to sort for the largest valueâ€”it returns [0,0,0,0,1,0,0,0,0].\n",
    "\n",
    "\n",
    "# Compile and train the model==============================================================\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(training_images, training_labels, epochs=5, callbacks=[callbacks])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
